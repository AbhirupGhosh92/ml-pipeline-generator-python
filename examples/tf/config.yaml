# Config file for AI Pipeline.

project_id: "cchatterjee-sandbox"
bucket_id: "cchatterjee-sandbox"
region: "us-central1"
# We will have to think how we want to handle custom, if we want to at all
scale_tier: "STANDARD_1"
runtime_version: "1.15"
python_version: "3.7"
package_name: "ai_pipeline"
machine_type_pred: "n1-standard-4"

data:
    schema:
        - "age"
        - "workclass"
        - "education_num"
        - "marital_status"
        - "occupation"
        - "relationship"
        - "race"
        - "capital_gain"
        - "capital_loss"
        - "hours_per_week"
        - "native_country"
        - "income_bracket"
    train: "gs://cchatterjee-sandbox/tf_model_demo_v1/data/adult.data.csv"
    evaluation: "gs://cchatterjee-sandbox/tf_model_demo_v1/data/adult.test.csv"
    prediction:
        input_data_paths:
            - "gs://cchatterjee-sandbox/tf_model_demo_v1/inputs/*"
        input_format: "JSON"
        output_format: "JSON"

model:
    name: "tf_model_demo_v1"
    path: "examples.tf.tf_model"
    target: "income_bracket"
    metrics:
        - "accuracy"

model_params:
    input_args:
        first_layer_size:
            type: "int"
            help: "Size of the NN first layer."
            default: 50
        num_layers:
            type: "int"
            help: "Number of layers in the NN."
            default: 5
        max_steps:
            default: 1000
    hyperparam_config: "examples/tf/hptuning_config.yaml"
    explain_output:
        explain_type: "sampledShapleyAttribution"
        explain_param:
            name: "numPaths"
            value: 40
